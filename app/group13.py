# -*- coding: utf-8 -*-
"""group13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10l1atFCeXCKtJRFyuZ5Eeonan-Vlwi28
"""

# !cp '/content/drive/MyDrive/13.zip' '/content/'

# !unzip '13.zip'

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Define a simple model architecture
def create_model(input_shape, output_shape):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(output_shape)  # Adjust output_shape based on your label's dimensionality
    ])
    return model

def load_data(data_dir, num_coordinates=4):
    images = []
    labels = []

    for root, dirs, files in os.walk(data_dir):
        if 'images' in dirs and 'labels' in dirs:
            images_folder = os.path.join(root, 'images')
            labels_folder = os.path.join(root, 'labels')

            for image_file in os.listdir(images_folder):
                if image_file.endswith('.jpg'):
                    img_path = os.path.join(images_folder, image_file)
                    img = cv2.imread(img_path)
                    img = cv2.resize(img, (224, 224))  # Adjust size as needed
                    images.append(img)

                    label_file = image_file.replace('.jpg', '.txt')
                    label_path = os.path.join(labels_folder, label_file)

                    if os.path.exists(label_path):
                        with open(label_path, 'r') as file:
                            label_str = file.read().strip().split()
                            label = list(map(float, label_str[1:]))[:num_coordinates]  # Exclude the class and limit coordinates
                            labels.append(label + [0.0] * (num_coordinates - len(label)))  # Pad with zeros if needed

                            print(f"Processed Image: {img_path}")
                            print(f"Processed Label: {label_path}")
                            print(f"Image Shape: {img.shape}")
                            print(f"Label Values: {label}")
                    else:
                        print(f"No label found for {image_file}. Skipping...")

    if len(images) != len(labels):
        raise ValueError("Mismatch between images and labels.")

    return np.array(images), np.array(labels)

# Define the input and output shapes
input_shape = (224, 224, 3)  # Example input shape (height, width, channels)
output_shape = 4  # Example output shape (num_coordinates)

# Create the model
model = create_model(input_shape, output_shape)

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Load data using the load_data function
train_images, train_labels = load_data('13/train')
train_labels = np.array(train_labels)  # Convert labels to NumPy array

if len(train_labels) == 0:
    raise ValueError("The dataset is empty.")

# Train the model
model.fit(train_images, train_labels, epochs=10, batch_size=32)

valid_images, valid_labels = load_data('13/valid')
valid_labels = np.array(valid_labels)  # Convert labels to NumPy array

if len(valid_labels) == 0:
    raise ValueError("The validation dataset is empty.")

# Evaluate the model on the validation data
evaluation = model.evaluate(valid_images, valid_labels)

# Load test data
test_images, test_labels = load_data('13/test')
test_labels = np.array(test_labels)  # Convert labels to NumPy array

if len(test_labels) == 0:
    raise ValueError("The test dataset is empty.")

# Test the model on the test data
results = model.evaluate(test_images, test_labels)

import cv2
import numpy as np

# Function to preprocess a single image
def preprocess_single_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, (224, 224))  # Adjust size as needed
    img = img.astype('float32') / 255.0  # Normalize pixel values (assuming 0-255 range)
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    return img

# Path to the single image you want to test
single_image_path = '/content/13/test/images/20230812_210244_jpg.rf.a2373a15c967eb6a157295e74fc71f45.jpg'

# Preprocess the single image
processed_single_image = preprocess_single_image(single_image_path)

# Get model predictions for the single image
predictions = model.predict(processed_single_image)

print("Predictions:", predictions)

#Make a model file
import joblib
joblib.dump(model, 'group13.py')